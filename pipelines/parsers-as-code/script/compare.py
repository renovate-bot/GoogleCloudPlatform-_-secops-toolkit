#! /usr/bin/env python3
# Copyright 2026 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import argparse
import logging
import os
import subprocess
import sys
import yaml
from config import PARSERS_ROOT_DIR, LOGS_FOLDER_NAME, EVENTS_FOLDER_NAME
from utils import compare_yaml_files, process_data_for_dump, generate_event_files
from models import ParserError, ParserState, ParserExtensionState, ParserType
import base64

LOGGER = logging.getLogger("pac")


class ParserComparator:
    """Compares events generated by two versions of a parser."""

    def __init__(self, log_type: str, client=None):
        self.log_type = log_type
        self.parser_dir = os.path.join(PARSERS_ROOT_DIR, log_type)
        self.logs_dir = os.path.join(self.parser_dir, LOGS_FOLDER_NAME)
        self.events_dir = os.path.join(self.parser_dir, EVENTS_FOLDER_NAME)

        if client:
            self.client = client
        else:
            from parser_manager import ParserManager
            self.manager = ParserManager()
            self.client = self.manager.client

    def _read_file(self, filename: str) -> str | None:
        path = os.path.join(self.parser_dir, filename)
        if not os.path.exists(path):
            return None
        with open(path, "r", encoding="utf-8") as f:
            return f.read()

    def _read_git_file(self,
                       filename: str,
                       branch: str = "main") -> str | None:
        """Reads a file from a specific git branch."""
        try:
            repo_path = f"parsers/{self.log_type}/{filename}"
            LOGGER.info(
                f"Attempting to fetch {repo_path} from branch '{branch}'...")
            result = subprocess.run(["git", "show", f"{branch}:{repo_path}"],
                                    capture_output=True,
                                    text=True,
                                    check=True)
            return result.stdout
        except subprocess.CalledProcessError as e:
            LOGGER.warning(
                f"Could not fetch {filename} from {branch}: {e.stderr.strip()}"
            )
            return None
        except Exception as e:
            LOGGER.error(f"Error fetching from git: {e}")
            return None

    def _flatten_single_event_dict(self, d, parent_key='', sep='.'):
        items = []
        for k, v in d.items():
            new_key = f"{parent_key}{sep}{k}" if parent_key else k
            if isinstance(v, dict):
                items.extend(
                    self._flatten_single_event_dict(v, new_key,
                                                    sep=sep).items())
            elif isinstance(v, list):
                for i, item in enumerate(v):
                    if isinstance(item, dict):
                        items.extend(
                            self._flatten_single_event_dict(item,
                                                            f"{new_key}[{i}]",
                                                            sep=sep).items())
                    else:
                        items.append((f"{new_key}[{i}]", item))
            else:
                items.append((new_key, v))
        return dict(items)

    def _extract_all_flat_events(self, events_data):
        """Extracts all individual events from the structure and flattens them."""
        flat_events = []

        if isinstance(events_data, list):
            for entry in events_data:
                # Check for "events" wrapper (legacy/specific format) or just raw list
                if isinstance(entry,
                              dict) and "events" in entry and isinstance(
                                  entry["events"], list):
                    for sub in entry["events"]:
                        flat_events.append(
                            self._flatten_single_event_dict(sub))
                # Handle list of lists (batch results from run_parser)
                elif isinstance(entry, list):
                    for sub in entry:
                        flat_events.append(
                            self._flatten_single_event_dict(sub))
                else:
                    flat_events.append(self._flatten_single_event_dict(entry))
        elif isinstance(events_data, dict):
            flat_events.append(self._flatten_single_event_dict(events_data))

        return flat_events

    def _compare_hierarchical(self, old_events_raw, new_events_raw):
        """Structurally compares old and new events and returns changed keys."""
        flat_old = self._extract_all_flat_events(old_events_raw)
        flat_new = self._extract_all_flat_events(new_events_raw)

        changed_keys = {}

        # Compare pairwise (assuming order is preserved)
        max_len = max(len(flat_old), len(flat_new))

        for i in range(max_len):
            o = flat_old[i] if i < len(flat_old) else {}
            n = flat_new[i] if i < len(flat_new) else {}

            all_keys = set(o.keys()) | set(n.keys())
            for k in all_keys:
                # Ignore noisy fields
                if "timestamp" in k.lower() or "etag" in k.lower():
                    continue

                in_old = k in o
                in_new = k in n

                if in_old and not in_new:
                    changed_keys.setdefault(k, set()).add("REMOVED")
                elif not in_old and in_new:
                    changed_keys.setdefault(k, set()).add("ADDED")
                elif in_old and in_new and o[k] != n[k]:
                    changed_keys.setdefault(k, set()).add("MODIFIED")

        return changed_keys

    def compare_content(self, old_parser: str, old_ext: str | None,
                        new_parser: str, new_ext: str | None) -> str:
        """Compares events generated by old and new parser/extension content for all log files."""
        report = []

        # 1. Generate events for ALL logs using shared utility
        # New -> <filename>.yaml
        # Old -> <filename>_old.yaml

        results_new = generate_event_files(self.client,
                                           self.log_type,
                                           new_parser,
                                           new_ext,
                                           self.logs_dir,
                                           self.events_dir,
                                           file_suffix="")
        results_old = generate_event_files(self.client,
                                           self.log_type,
                                           old_parser,
                                           old_ext,
                                           self.logs_dir,
                                           self.events_dir,
                                           file_suffix="_old")

        if not results_new and not results_old:
            return "Skipped comparison: No logs processed or generation failed."

        # Aggregate stats
        total_events_old = 0
        total_events_new = 0
        all_diffs = []
        all_hierarchical_changes = {
        }  # Key: field_name, Value: set of change types

        # Iterate over all logs found in either result set
        all_logs = sorted(set(results_new.keys()) | set(results_old.keys()))

        for log_file in all_logs:
            path_new, count_new, events_new = results_new.get(
                log_file, (None, 0, []))
            path_old, count_old, events_old = results_old.get(
                log_file, (None, 0, []))

            total_events_new += count_new
            total_events_old += count_old

            if path_new and path_old:
                # Compare per file
                file_diffs = compare_yaml_files(path_old, path_new, [
                    "eventTimestamp", "timestamp", "collectedTimestamp", "etag"
                ])
                if file_diffs:
                    all_diffs.append(f"--- Diff for {log_file} ---")
                    all_diffs.extend(file_diffs)

                # Hierarchical comparison
                changes = self._compare_hierarchical(events_old, events_new)
                for k, v in changes.items():
                    all_hierarchical_changes.setdefault(k, set()).update(v)

        def add_line(text=""):
            report.append(text)
            print(text)

        add_line("\n" + "=" * 60)
        add_line(f"COMPARISON REPORT: {self.log_type}")
        add_line("=" * 60)
        add_line(f"Total Events Generated (Old): {total_events_old}")
        add_line(f"Total Events Generated (New): {total_events_new}")

        if total_events_old != total_events_new:
            add_line(
                f"WARNING: Event count mismatch! (Diff: {total_events_new - total_events_old})"
            )
        else:
            add_line("Event counts match.")

        if all_hierarchical_changes:
            add_line("-" * 60)
            add_line(
                f"Changed Fields ({len(all_hierarchical_changes)} detected across all logs):"
            )
            for k in sorted(all_hierarchical_changes.keys()):
                types = ", ".join(sorted(all_hierarchical_changes[k]))
                add_line(f" - {k} ({types})")
        else:
            add_line("-" * 60)
            add_line(
                "No field-level changes detected (excluding timestamps/etags)."
            )

        add_line("-" * 60)

        if all_diffs:
            add_line(f"Raw Line Discrepancies ({len(all_diffs)} lines):")
            add_line("(See execution logs for full diff details)")
            add_line("-" * 40)

            # Print full details to stderr so they appear in logs but not PR comment
            print("-" * 40, file=sys.stderr)
            print(f"RAW LINE DISCREPANCIES ({len(all_diffs)} lines):",
                  file=sys.stderr)
            if len(all_diffs) > 500:
                print("\n".join(all_diffs[:500]), file=sys.stderr)
                print(f"... and {len(all_diffs) - 500} more lines.",
                      file=sys.stderr)
            else:
                print("\n".join(all_diffs), file=sys.stderr)
            print("-" * 40, file=sys.stderr)
        else:
            add_line("No raw YAML validation differences found.")
        add_line("=" * 60 + "\n")

        return "\n".join(report)

    def _get_active_content(self, log_type: str,
                            is_extension: bool) -> str | None:
        """Fetches the content of an active parser or extension from SecOps."""
        try:
            if is_extension:
                extensions = self.client.list_parser_extensions(log_type)
                if not "parserExtensions" in extensions:
                    return None
                for ext in extensions["parserExtensions"]:
                    if ext.get(
                            "state"
                    ) == ParserExtensionState.LIVE.value and "cbnSnippet" in ext:
                        return base64.b64decode(
                            ext["cbnSnippet"]).decode('utf-8')
            else:
                parsers = self.client.list_parsers(log_type)
                for parser in parsers:
                    if parser.get(
                            "state"
                    ) == ParserState.ACTIVE.value and "cbn" in parser:
                        return base64.b64decode(parser["cbn"]).decode('utf-8')
        except Exception as e:
            LOGGER.error(f"Failed to fetch active content: {e}")
            return None
        return None

    def run(self, branch: str = None):
        target = "SecOps Active"
        LOGGER.info(
            f"Starting comparison for log type: {self.log_type} against {target}"
        )

        # Load parser configurations
        parser_new = self._read_file("parser.conf")
        parser_ext_new = self._read_file("parser_extension.conf")

        # Fetch from SecOps
        parser_old = self._get_active_content(self.log_type,
                                              is_extension=False)
        parser_ext_old = self._get_active_content(self.log_type,
                                                  is_extension=True)

        if not parser_old and branch:
            LOGGER.info(
                f"No active parser found in SecOps. Falling back to git branch '{branch}'..."
            )
            parser_old = self._read_git_file("parser.conf", branch)
            parser_ext_old = self._read_git_file("parser_extension.conf",
                                                 branch)
            target = f"git branch '{branch}'"

        if not parser_new:
            LOGGER.error("parser.conf not found locally.")
            return "parser.conf not found locally."
        if not parser_old:
            LOGGER.error(
                f"Baseline configuration not found (checked SecOps Active and git '{branch}'). Cannot compare."
            )
            return f"Baseline configuration not found (checked SecOps Active and git '{branch}')."

        LOGGER.info(f"Comparing against {target}...")
        return self.compare_content(parser_old, parser_ext_old, parser_new,
                                    parser_ext_new)
